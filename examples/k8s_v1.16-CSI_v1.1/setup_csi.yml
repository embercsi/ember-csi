# We need to retry this command, as the API may still be restarting
- name: Allow Node role to create attachments
  shell: "kubectl get -o yaml clusterroles/system:node | perl -0pe 's/volumeattachments\n  verbs:\n/volumeattachments\n  verbs:\n  - create\n  - list\n  - update\n  - watch\n  - patch\n  - delete\n/' | kubectl replace -f -"
  # register: res
  # until: res | success
  # retries: 5
  # delay: 10

- name: Bind master to Node role
  shell: 'kubectl patch clusterrolebindings/system:node -p ''{"subjects": [{"kind": "User", "name": "system:node:master", "namespace": "kube-system"}]}'''

- name: Bind nodes to Node role
  shell: "kubectl get -o yaml clusterrolebindings/system:node | perl -0pe 's/subjects:\n/subjects:\n- kind: User\n{{'  '}}name: system:node:{{ item }}\n{{'  '}}namespace: kube-system\n/' | tee -a bind_node.txt | kubectl replace -f -"
  with_items: "{{ groups['nodes'] }}"

- name: Remove API NodeRestriction
  lineinfile:
    path: /etc/kubernetes/manifests/kube-apiserver.yaml
    regexp: '- --enable-admission-plugins=NodeRestriction'
    state: absent

# We would normally pass the features-gates to kubeadm init, but it complains
# about not knowing the features
- name: Remove API Node authorization and set required features
  command: sed -i 's/    - --authorization-mode=Node,RBAC/    - --authorization-mode=RBAC\n    - --feature-gates=VolumeSnapshotDataSource=true,CSIDriverRegistry=true/' /etc/kubernetes/manifests/kube-apiserver.yaml

- name: Add features to scheduler
  command: sed -i 's/    - kube-scheduler/    - kube-scheduler\n    - --feature-gates=VolumeSnapshotDataSource=true,CSIDriverRegistry=true/' /etc/kubernetes/manifests/kube-scheduler.yaml

- name: Add features to manager
  command: sed -i 's/    - kube-controller-manager/    - kube-controller-manager\n    - --feature-gates=VolumeSnapshotDataSource=true,CSIDriverRegistry=true/' /etc/kubernetes/manifests/kube-controller-manager.yaml

- name: Restart API containers
  shell: docker restart $(docker ps --filter "name=apiserver_kube" --format "{{'{{'}}.ID{{'}}'}}") || true

- name: Restart Scheduler and Manager containers
  shell: docker restart $(docker ps --filter "name=scheduler_kube|manager_kube" --format "{{'{{'}}.ID{{'}}'}}") || true

- name: Create kubeyml directory
  file:
    path: /home/vagrant/kubeyml
    state: directory
    owner: vagrant
    group: vagrant

- name: Create kubeyml backend directories
  file:
    path: /home/vagrant/kubeyml/{{ item.path }}
    state: directory
    owner: vagrant
    group: vagrant
  with_filetree: kubeyml/
  when: item.state == 'directory'

- name: Copy rendered YAML files
  template:
    src: "{{ item.src }}"
    dest: "/home/vagrant/kubeyml/{{ item.path }}"
    owner: vagrant
    group: vagrant
  with_filetree: kubeyml/
  when: item.state == 'file' and not item.path.endswith('.swp')

- wait_for: timeout=20
  delegate_to: localhost
  become: no

# We don't support kubernetes CSDriver additional info, so we don't pass pod-info-mount-version to the cluster-driver-registrar
# https://github.com/kubernetes/kubernetes/blob/8f1082c6aff6df3cb5e103474d9d846b6f8ebf90/pkg/volume/csi/csi_mounter.go#L256

- wait_for: timeout=90
  delegate_to: localhost
  become: no

- name: Set CSI LVM controller
  command: kubectl create -f /home/vagrant/kubeyml/lvm/01-controller.yml

- wait_for: timeout=90
  delegate_to: localhost
  become: no

- name: Start CSI LVM nodes
  command: kubectl create -f /home/vagrant/kubeyml/lvm/02-node.yml

- name: Create LVM Storage Class
  command: kubectl create -f /home/vagrant/kubeyml/lvm/03-storage-class.yml

# We need to wait for VolumeSnapshotClass to exist
- wait_for: timeout=180
  delegate_to: localhost
  become: no

- name: Create LVM Snapshot Storage Class
  command: kubectl create -f /home/vagrant/kubeyml/lvm/04-snapshot-class.yml

- name: Set CSI Ceph controller
  command: kubectl create -f /home/vagrant/kubeyml/rbd/01-controller.yml

- name: Start CSI Ceph nodes
  command: kubectl create -f /home/vagrant/kubeyml/rbd/02-node.yml

- name: Create Ceph Storage Class
  command: kubectl create -f /home/vagrant/kubeyml/rbd/03-storage-class.yml

- name: Create Ceph Snapshot Storage Class
  command: kubectl create -f /home/vagrant/kubeyml/rbd/04-snapshot-class.yml

- wait_for: timeout=60
  delegate_to: localhost
  become: no

- name: Change Ceph default features
  command: kubectl exec csi-rbd-0 -c csi-driver -- /bin/bash -c 'sed -i "s/\[global\]/[global]\nrbd default features = 3/" /etc/ceph/ceph.conf'
